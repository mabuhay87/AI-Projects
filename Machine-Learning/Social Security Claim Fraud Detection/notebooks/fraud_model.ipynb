{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fd44cf4",
   "metadata": {},
   "source": [
    "# Social Security Claim Fraud Detection\n",
    "\n",
    "This notebook builds a complete **fraud detection pipeline** for synthetic Social Security Administration (SSA)-style claims data.\n",
    "\n",
    "**Goals:**\n",
    "- Predict which claims are likely to be fraudulent (`is_fraud`)\n",
    "- Handle class imbalance (fraud is rare)\n",
    "- Evaluate models with fraud-focused metrics (recall, precision, PR AUC)\n",
    "- Use SHAP for explainability\n",
    "- Export fraud risk scores for inspection / BI dashboards\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c924c9f",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade4ae0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If you're in Google Colab, you may need to install:\n",
    "# !pip install xgboost imbalanced-learn shap\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    average_precision_score\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28979601",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f931543",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "data_path = os.path.join(\"..\", \"data\", \"ssa_claim_fraud_dataset.csv\")\n",
    "df = pd.read_csv(data_path)\n",
    "df.shape, df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116a176e",
   "metadata": {},
   "source": [
    "## 3. Basic EDA & Target Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adb3d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['is_fraud'].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8d4897",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.countplot(x='is_fraud', data=df)\n",
    "plt.title('Fraud vs Non-Fraud Claims')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fee4ea",
   "metadata": {},
   "source": [
    "## 4. Feature Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a09724",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_col = \"is_fraud\"\n",
    "y = df[target_col]\n",
    "X = df.drop(columns=[target_col, \"claim_id\", \"person_id\"])\n",
    "\n",
    "cat_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols = X.select_dtypes(exclude=[\"object\"]).columns.tolist()\n",
    "\n",
    "cat_cols, num_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae8cac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocessor: OneHotEncode categoricals, pass through numerics\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", \"passthrough\", num_cols),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2304d46b",
   "metadata": {},
   "source": [
    "## 5. Train/Test Split & SMOTE for Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49769ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756888ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# First, fit the preprocessor on training data and transform\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_test_proc = preprocessor.transform(X_test)\n",
    "\n",
    "# Apply SMOTE to handle class imbalance (fraud minority class)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_proc, y_train)\n",
    "\n",
    "X_train_proc.shape, X_train_res.shape, y_train.value_counts(), y_train_res.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93036047",
   "metadata": {},
   "source": [
    "## 6. Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5c1bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Logistic Regression (baseline)\n",
    "log_model = LogisticRegression(max_iter=2000)\n",
    "log_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=12,\n",
    "    class_weight=\"balanced_subsample\",\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42,\n",
    "    scale_pos_weight=3  # fraud minority class\n",
    ")\n",
    "xgb_model.fit(X_train_res, y_train_res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dcad81",
   "metadata": {},
   "source": [
    "## 7. Evaluation (Fraud-Focused Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89369b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval_model(model, X_test_proc, y_test, name=\"Model\"):\n",
    "    y_prob = model.predict_proba(X_test_proc)[:, 1]\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "    roc = roc_auc_score(y_test, y_prob)\n",
    "    pr_auc = average_precision_score(y_test, y_prob)\n",
    "    print(f\"{name} - ROC AUC: {roc:.4f}, PR AUC: {pr_auc:.4f}\\n\")\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"Logistic Regression:\")\n",
    "eval_model(log_model, X_test_proc, y_test, \"Logistic Regression\")\n",
    "\n",
    "print(\"\\nRandom Forest:\")\n",
    "eval_model(rf_model, X_test_proc, y_test, \"Random Forest\")\n",
    "\n",
    "print(\"\\nXGBoost:\")\n",
    "eval_model(xgb_model, X_test_proc, y_test, \"XGBoost\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f74a7ca",
   "metadata": {},
   "source": [
    "## 8. SHAP Explainability (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16686f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For SHAP, we need a feature matrix (dense) and feature names\n",
    "# X_train_proc and X_test_proc may be sparse; convert small sample to dense\n",
    "import scipy.sparse as sp\n",
    "\n",
    "X_test_sample = X_test_proc[:1000]\n",
    "if sp.issparse(X_test_sample):\n",
    "    X_test_sample = X_test_sample.toarray()\n",
    "\n",
    "# Get feature names from preprocessor\n",
    "ohe = preprocessor.named_transformers_['cat']\n",
    "cat_feature_names = ohe.get_feature_names_out(cat_cols)\n",
    "feature_names = list(cat_feature_names) + num_cols\n",
    "\n",
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "shap_values = explainer.shap_values(X_test_sample)\n",
    "\n",
    "shap.summary_plot(shap_values, X_test_sample, feature_names=feature_names, show=False)\n",
    "plt.title(\"SHAP Summary - Fraud Model\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932d330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SHAP bar plot\n",
    "shap.summary_plot(shap_values, X_test_sample, feature_names=feature_names, plot_type=\"bar\", show=False)\n",
    "plt.title(\"SHAP Feature Importance - Fraud Model\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200ed6ee",
   "metadata": {},
   "source": [
    "## 9. Export Fraud Risk Scores for BI / Case Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdde4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Recompute processed full feature matrix for entire dataset\n",
    "X_full_proc = preprocessor.transform(X)\n",
    "\n",
    "# Get fraud probabilities from XGBoost\n",
    "full_prob = xgb_model.predict_proba(X_full_proc)[:, 1]\n",
    "full_pred = (full_prob >= 0.5).astype(int)\n",
    "\n",
    "def risk_level(p):\n",
    "    if p >= 0.8:\n",
    "        return \"High\"\n",
    "    elif p >= 0.5:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Low\"\n",
    "\n",
    "risk_levels = [risk_level(p) for p in full_prob]\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "    \"claim_id\": df[\"claim_id\"],\n",
    "    \"person_id\": df[\"person_id\"],\n",
    "    \"fraud_flag_pred\": full_pred,\n",
    "    \"fraud_probability\": full_prob,\n",
    "    \"fraud_risk_level\": risk_levels\n",
    "})\n",
    "\n",
    "pred_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc7e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save predictions to CSV\n",
    "pred_csv_path = os.path.join(\"..\", \"data\", \"fraud_predictions.csv\")\n",
    "pred_df.to_csv(pred_csv_path, index=False)\n",
    "print(f\"Saved fraud predictions to {pred_csv_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
